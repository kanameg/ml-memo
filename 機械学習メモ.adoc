:lang: ja
:doctype: book

:chapter-label:
:sectnums:

= 機械学習ノート

== 特徴量の生成

=== 特徴量とは
機械学習で学習や推測にもちるデータの種類のことを特徴量という。
機械学習で用いるモデルは数値データのみしか入力できない（文字や文字列データは入力不可）ため、入力する元のデータの特徴量は数値化する必要がある。
また選択したモデルによって数値の取りか使い方が異なるため、モデルによって特徴量の数値の意味や大小関係などを考慮する必要がある。
例えば、GBDT(Gradient Boosting Decision Tree)では、決定木が使われているため以下のような特徴がある。

* 数値の大きさにには意味がない、数値の大小関係に意味がある
* 欠損値があっても、そのまま扱うことができる

数値の大きさに意味がないため、数値データの範囲や分布を気にする必要があまりない。また欠損値がそのままでもある程度問題がないため非常に扱いやすいモデルとも言える。
もちろん欠損値は埋められるときには埋めた方が精度向上する場合もある。分布やデータの範囲も気にした方が精度向上する場合もある。
それに対して、NN(ニューラルネットワーク)では、以下のような特徴がある。

* 数値に意味があるので、大きさに影響される
* 欠損値を取り扱えないので欠損値を処理する必要がある

また、線形モデルなどでは特徴量の関係が線形でないと精度が出ないモデルの場合、対数を取ったりするなど非線形な変換をする必要がある。

=== 欠損値とは
データ生成時の不備や、そもそも値が存在しない（データ数が0の場合の平均値）などにより欠損したデータのことを欠損値という。

==== 欠損値の扱い
欠損値の扱いとしては以下の方法が考えられる。

===== 欠損値をそのままで扱う
GBDTなどのモデルでは欠損値をそのままで扱うことも可能。その場合は欠損値をそのままにしておいてもよい。
ただし補完できる場合は推論精度が向上する場合もあるので、両方を試した方がよい場合もある。

scikit-learnのランダムフォレストなどは欠損値を扱えないため、-9999などの範囲外の値で補完することにより欠損値のまま扱うことも可能。

===== 欠損値を代表値で補完
欠損発生の理由が偶然の場合やランダムである場合は、代表値で補完した方が精度向上する場合もある。逆にランダムでない場合は、欠損であることに意味のある場合があるので、補完をしないほうが良い。

代表値で補完する場合は、平均値や中央値などを利用する。
またグループ毎で代表値が異なりそうな場合は、別のカテゴリ変数でグループを作りグループ毎の平均をとって補完したりする。

欠損している値がカテゴリ変数の場合は、データ全体やグループ毎で最も多い値(mode)へ置き換えるなどの方法がある。

===== 欠損値を予測
欠損している変数が他の変数と関連性がある場合は、他の変数から予測することで補完が可能。

欠損値のある変数を目的変数として、その他を特徴量として予測モデルを作成する。
この際に本来の目的変数を特徴量に入れるとテストデータの方の補完ができないため特徴量に入れない。
そのため、テストデータも学習データとして使用してもよい。作成したモデルで欠損値のデータを予測して補完する。

===== 欠損値から新たな特徴量を生成
欠損値がランダムに発生しているわけではない場合、欠損値から新たな特徴量を生成可能な場合がある。
欠損であったという2値情報を生成することで欠損情報を保存できる（欠損値自体は補完することも可能）。
レコードごとに欠損値の数をカウントし、その数を特徴量とすることも可能。

==== 欠損値の補完
欠損値を補完する場合、Pandasでは、欠損値を `NaN` にしておくことで `fillna` 関数を利用することで補完可能。

```
df['col'] = df['col1'].fillna(0)  # 0で補完
df['col'] = df['col1'].fillna(df['col1'].mean())  # 平均値で補完
```



